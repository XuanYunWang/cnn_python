{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05ebc039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from obspy import UTCDateTime, Stream, Trace,read\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import model_cnn_cls\n",
    "import pandas as pd\n",
    "import pygmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7361ac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/home/sysop/share/drive-download-20220316T143533Z-001\"\n",
    "#path=\"/home/sysop/share/2021_10_felt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c520e695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_showname(path):\n",
    "    afile_name=[]\n",
    "    pfile_name=[]\n",
    "    for fname in os.listdir(path):\n",
    "        if fname[-3]==\"A\":\n",
    "            afile_name.append(fname)\n",
    "        if fname[-3]==\"P\":\n",
    "            pfile_name.append(fname)\n",
    "    return afile_name,pfile_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2339d44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpackAfile(infile):\n",
    "\n",
    "# == opening Afile ==\n",
    "    b = os.path.getsize(infile)\n",
    "    FH = open(infile, 'rb')\n",
    "    line = FH.read(b)\n",
    "    fileHeader = struct.unpack(\"<4s3h6bh6s\", line[0:24])\n",
    "\n",
    "    fileLength = fileHeader[3]\n",
    "    port = fileHeader[10]\n",
    "    # FirstStn = fileHeader[11][0:4].decode('ASCII').rstrip()\n",
    "# =================================Header=================================\n",
    "\n",
    "    portHeader = []\n",
    "    for i in range(24, port * 32, 32):\n",
    "        port_data = struct.unpack(\"<4s4s3sbh2b4s12b\", line[i:i+32])\n",
    "        portHeader.append(port_data)\n",
    "\n",
    "# =================================Data===================================\n",
    "\n",
    "    dataStartByte = 24+int(port)*32\n",
    "    dataPoint = 3*int(port)*int(fileLength)*100\n",
    "    times = int(port)*3*4\n",
    "    data = []\n",
    "\n",
    "    data = struct.unpack(\"<%di\" % dataPoint, line[dataStartByte:dataStartByte + dataPoint*4])\n",
    "\n",
    "\n",
    "    portHeader = np.array(portHeader)\n",
    "    data = np.array(data)\n",
    "    idata = data.reshape((3,port,fileLength*100),order='F')\n",
    "\n",
    "#== write to obspy Stream --\n",
    "    sttime = UTCDateTime(fileHeader[1], fileHeader[4], fileHeader[5], fileHeader[6], fileHeader[7], fileHeader[8], fileHeader[2])\n",
    "    npts = fileHeader[3]*fileHeader[9]\n",
    "    samp = fileHeader[9]\n",
    "    afst = Stream()\n",
    "    \n",
    "    for stc in range(fileHeader[10]):\n",
    "        stn = portHeader[stc][0].decode('ASCII').rstrip()\n",
    "        instrument = portHeader[stc][1].decode('ASCII').rstrip()\n",
    "        loc = '0'+str(portHeader[stc][6].decode('ASCII'))\n",
    "        net = str(portHeader[stc][7].decode('ASCII')).rstrip()\n",
    "        GPS = int(portHeader[stc][3])\n",
    "        \n",
    "        # remove GPS unlock or broken station\n",
    "        if ( GPS == 1 or GPS == 2 ):\n",
    "            chc = 0\n",
    "            if instrument == 'FBA':\n",
    "                chc = 1\n",
    "            elif instrument == 'SP':\n",
    "                chc = 4\n",
    "            elif instrument == 'BB':\n",
    "                chc = 7\n",
    "            \n",
    "            for ch in range(3):\n",
    "                chn = 'Ch'+str(chc+ch)\n",
    "                \n",
    "                stats = {'network': net, 'station': stn, 'location': loc,\n",
    "                        'channel': chn, 'npts': npts, 'sampling_rate': samp,\n",
    "                        'starttime': sttime}\n",
    "                \n",
    "                data = np.array(idata[ch][stc], dtype=float)\n",
    "                sttmp = Stream([Trace(data=data, header=stats)])\n",
    "                afst += sttmp\n",
    "\n",
    "    return afst\n",
    "\n",
    "def unpackPfile(infile):\n",
    "    \n",
    "    with open(infile) as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    tmp = lines[0]\n",
    "    year = int(tmp[1:5])\n",
    "    month = int(tmp[5:7])\n",
    "    day = int(tmp[7:9])\n",
    "    hour = int(tmp[9:11])\n",
    "    minute = int(tmp[11:13])\n",
    "    sec = float(tmp[13:19])\n",
    "    \n",
    "    lat_d = float(tmp[19:21])\n",
    "    lat_m = float(tmp[21:26])\n",
    "    \n",
    "    lon_d = float(tmp[26:29])\n",
    "    lon_m = float(tmp[29:34])\n",
    "    dep=float(tmp[34:40])\n",
    "    dt = datetime(year,month,day,hour,minute,int(sec//1),int(sec%1 * 1000000))\n",
    "    mag = float(tmp[40:44])\n",
    "\n",
    "    pfile_info = {}\n",
    "    pfile_info[\"ori_time\"] = dt\n",
    "    pfile_info[\"mag\"] = mag\n",
    "    pfile_info[\"lat\"] = lat_d + lat_m/60.0\n",
    "    pfile_info[\"lon\"] = lon_d + lon_m/60.0\n",
    "    pfile_info[\"dep\"] = dep\n",
    "    \n",
    "    intensity = {}\n",
    "    arrival_time = {}\n",
    "    weighting = {}\n",
    "    pga = {}\n",
    "    for i in lines[1:]:\n",
    "        sta = i[:5].strip() # strip 去掉左右空格\n",
    "        weighting[sta] = int(float(i[35:39]))\n",
    "        if i[76:77]==\" \":\n",
    "            intensity[sta] = int(0)\n",
    "        else:\n",
    "            intensity[sta] = int(i[76:77])\n",
    "        if i[78:83]==\"     \":\n",
    "            pga[sta] = int(0)\n",
    "        else:\n",
    "            pga[sta] = (i[78:83])\n",
    "        arrival_time[sta] = pfile_info[\"ori_time\"].replace(minute=int(i[21:23]),second=0,microsecond=0) + timedelta(seconds=float(i[23:29]))\n",
    "        arrival_time[sta].microsecond * 10**-6\n",
    "    pfile_info[\"intensity\"] = intensity\n",
    "    pfile_info[\"arrival_time\"] = arrival_time\n",
    "\n",
    "    pfile_info[\"weighting\"] = weighting\n",
    "    pfile_info[\"pga\"] = pga\n",
    "    \n",
    "    return pfile_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "630c2c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apfile_read(pfile_name,afile_name):\n",
    "    Pfile = unpackPfile(path+\"/\"+pfile_name)\n",
    "    Afile = unpackAfile(path+\"/\"+afile_name)\n",
    "    Afile_se = Afile.select(channel=\"*1\")\n",
    "    Afile_se += Afile.select(channel=\"*2\")\n",
    "    Afile_se += Afile.select(channel=\"*3\")\n",
    "    \n",
    "    e_latlon = [Pfile[\"lat\"],Pfile[\"lon\"]]\n",
    "    \n",
    "    return Pfile,Afile,Afile_se,e_latlon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5284b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor():\n",
    "    with open(\"nsta24.dat\",\"r\") as f:\n",
    "        data_nsta=f.readlines()\n",
    "        \n",
    "    data_factor={}\n",
    "    sta_lon_lat={}\n",
    "    for i in data_nsta:\n",
    "        i=i.strip()\n",
    "        if i[34:37]==\"CWB\" and i[39:42]==\"SMT\" and i[45:48]==\"FBA\" and i[100:]==\"99999999\":\n",
    "            data_factor[i[0:4].strip()]=[i[49:59],i[60:70],i[71:81]]\n",
    "            sta_lon_lat[i[0:4].strip()]=[i[5:13],i[14:21]]\n",
    "            \n",
    "    return data_factor,sta_lon_lat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca6485cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_factor(Afile_se,data_factor):\n",
    "    Afile_se_data=Stream()\n",
    "    for i in Afile_se.copy():\n",
    "        i.detrend()\n",
    "        if i.stats.network == \"SMT\":\n",
    "            if i.stats.channel == \"Ch1\":\n",
    "                if i.stats.station in data_factor.keys():\n",
    "                    i.data=i.data*float(data_factor[i.stats.station][0])\n",
    "                    Afile_se_data.append(i)\n",
    "            if i.stats.channel == \"Ch2\":\n",
    "                if i.stats.station in data_factor.keys():\n",
    "                    i.data=i.data*float(data_factor[i.stats.station][1])\n",
    "                    Afile_se_data.append(i)\n",
    "            if i.stats.channel == \"Ch3\":\n",
    "                if i.stats.station in data_factor.keys():\n",
    "                    i.data=i.data*float(data_factor[i.stats.station][2])\n",
    "                    Afile_se_data.append(i)\n",
    "    \n",
    "    return Afile_se_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96f5dadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_st(Afile_se_data,Pfile):\n",
    "    P_arr_time = Pfile[\"arrival_time\"]\n",
    "    Afile_se_5s=Stream()\n",
    "    sta_P1=[]\n",
    "    for i in Afile_se_data:\n",
    "        if i.stats.station in P_arr_time.keys():\n",
    "            sta_P1.append(i.stats.station)\n",
    "            Afile_se_5s.append(i.slice(UTCDateTime(P_arr_time[i.stats.station]),UTCDateTime(P_arr_time[i.stats.station])+4.99))\n",
    "    sta_P = np.unique(sta_P1).tolist()\n",
    "    return Afile_se_5s,sta_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83a4ebbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_array(Afile_se_5s,sta_P):\n",
    "    Afile_se_5s_data_123={}\n",
    "    for i in sta_P:\n",
    "        data_list_123=[]\n",
    "        for k in Afile_se_5s:\n",
    "            if i == k.stats.station:\n",
    "                data_list_123.append(k.data)\n",
    "        data_list_123 = np.unique(data_list_123,axis=0)\n",
    "        if data_list_123 != []:\n",
    "            Afile_se_5s_data_123[i]=np.array(data_list_123)\n",
    "    \n",
    "    return Afile_se_5s_data_123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a29d275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pga(Afile_se_5s_data_123,Pfile):\n",
    "    pga_data={}\n",
    "    for i in Afile_se_5s_data_123:\n",
    "        if len(Pfile[\"pga\"][i]) > 0:\n",
    "            pga_data[i]=float(Pfile[\"pga\"][i])\n",
    "        else:\n",
    "            pga_data[i]=0\n",
    "    return pga_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "622a7dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_txt(Pfile,afile_name,result):\n",
    "    #輸出result為txt檔\n",
    "    file = open(afile_name+'.txt', 'w')\n",
    "    file.write(str(Pfile[\"ori_time\"])+' '+str(Pfile[\"mag\"])+' '+str(Pfile[\"lat\"])+' '+str(Pfile[\"lon\"])+'%6s'%str(Pfile[\"dep\"])+'\\n')\n",
    "    for k,v in result.items():\n",
    "        file.write('%5s'%str(k)+' '+str(v[0])+' '+str(v[1])+' '+'%-11s'%str(v[2])+' '+'%-9s'%str(v[3])+' '+str(v[4])+' '+str(v[5])+'\\n')\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "be88dc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_read(afile_name,result,e_latlon): \n",
    "    #從txt讀取資料\n",
    "    data = f\"/home/sysop/share/{afile_name}.txt\"\n",
    "    data_df = pd.read_table(data,header = None,sep = \"\\s+\",skiprows=[0])\n",
    "    data_df.columns = [\"station\",\"lon\",\"lat\",\"probability_X\",\"probability_O\",\"predict\",\"pga\"]\n",
    "    \n",
    "    data_df_TN = data_df[(data_df[\"predict\"] == 0) & (data_df[\"pga\"]<80)]\n",
    "    data_df_TN = data_df_TN.reset_index(drop=True)\n",
    "    data_df_FN = data_df[(data_df[\"predict\"] == 0) & (data_df[\"pga\"]>=80)]\n",
    "    data_df_FN = data_df_FN.reset_index(drop=True)\n",
    "    data_df_TP = data_df[(data_df[\"predict\"] == 1) & (data_df[\"pga\"]>=80)]\n",
    "    data_df_TP = data_df_TP.reset_index(drop=True)\n",
    "    data_df_FP = data_df[(data_df[\"predict\"] == 1) & (data_df[\"pga\"]<80)]\n",
    "    data_df_FP = data_df_FP.reset_index(drop=True)\n",
    "    \n",
    "    return data_df_TN,data_df_FN,data_df_TP,data_df_FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c046160b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sysop/anaconda3/envs/eqt/lib/python3.7/site-packages/ipykernel-6.0.2-py3.7.egg/ipykernel_launcher.py:9: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "station: ALS\n",
      "Probability: [ 0.0723011  0.9276989]\n",
      "Predict: 1\n",
      "----------------------------------------\n",
      "station: ANP\n",
      "Probability: [ 0.97080606  0.02919391]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: BAC\n",
      "Probability: [ 0.96047586  0.03952412]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: CHK\n",
      "Probability: [ 0.00488757  0.9951125 ]\n",
      "Predict: 1\n",
      "----------------------------------------\n",
      "station: CHN1\n",
      "Probability: [ 0.9115486  0.0884514]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: CHN2\n",
      "Probability: [ 0.5388211   0.46117896]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: CHN3\n",
      "Probability: [ 0.9488953  0.0511047]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: CHN4\n",
      "Probability: [ 0.6364231   0.36357686]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: CHN5\n",
      "Probability: [ 0.04121041  0.9587895 ]\n",
      "Predict: 1\n",
      "----------------------------------------\n",
      "station: CHN8\n",
      "Probability: [ 0.93509036  0.06490964]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: CHY\n",
      "Probability: [ 0.92549336  0.07450662]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: EAS\n",
      "Probability: [ 0.9653706   0.03462938]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: ECB\n",
      "Probability: [  4.82042611e-04   9.99517918e-01]\n",
      "Predict: 1\n",
      "----------------------------------------\n",
      "station: ECL\n",
      "Probability: [ 0.9603326   0.03966738]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: ECS\n",
      "Probability: [ 0.14712614  0.85287386]\n",
      "Predict: 1\n",
      "----------------------------------------\n",
      "station: EGC\n",
      "Probability: [ 0.00510704  0.99489295]\n",
      "Predict: 1\n",
      "----------------------------------------\n",
      "station: EGS\n",
      "Probability: [ 0.97038347  0.02961655]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: EHP\n",
      "Probability: [ 0.8415109   0.15848917]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: EHY\n",
      "Probability: [ 0.00254799  0.99745196]\n",
      "Predict: 1\n",
      "----------------------------------------\n",
      "station: ELD\n",
      "Probability: [ 0.01815343  0.9818465 ]\n",
      "Predict: 1\n",
      "----------------------------------------\n",
      "station: ENA\n",
      "Probability: [ 0.91896707  0.08103296]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: ENT\n",
      "Probability: [ 0.9459291   0.05407086]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: ESL\n",
      "Probability: [ 0.021192    0.97880805]\n",
      "Predict: 1\n",
      "----------------------------------------\n",
      "station: ETL\n",
      "Probability: [ 0.7787021   0.22129793]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: ETM\n",
      "Probability: [ 0.11020952  0.8897905 ]\n",
      "Predict: 1\n",
      "----------------------------------------\n",
      "station: EYL\n",
      "Probability: [ 0.07221865  0.9277813 ]\n",
      "Predict: 1\n",
      "----------------------------------------\n",
      "station: HEN\n",
      "Probability: [ 0.9707525   0.02924756]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: HSN\n",
      "Probability: [ 0.9693626   0.03063744]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: HSN1\n",
      "Probability: [ 0.96732306  0.03267696]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: HWA\n",
      "Probability: [ 0.7195877  0.2804123]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: ILA\n",
      "Probability: [ 0.9703157   0.02968438]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: KNM\n",
      "Probability: [ 0.97078526  0.02921474]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: LAY\n",
      "Probability: [ 0.4108587   0.58914137]\n",
      "Predict: 1\n",
      "----------------------------------------\n",
      "station: MSU\n",
      "Probability: [ 0.970586    0.02941393]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: NCU\n",
      "Probability: [ 0.96824896  0.03175098]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: NHW\n",
      "Probability: [ 0.96993554  0.03006441]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: NHY\n",
      "Probability: [ 0.9668268   0.03317316]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: NJD\n",
      "Probability: [ 0.9566084   0.04339157]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: NJN\n",
      "Probability: [ 0.9622253   0.03777471]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: NNS\n",
      "Probability: [ 0.9621293   0.03787068]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: NOU\n",
      "Probability: [ 0.9707812   0.02921876]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: NSK\n",
      "Probability: [ 0.9661822   0.03381786]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: NST\n",
      "Probability: [ 0.96367604  0.03632397]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: NSY\n",
      "Probability: [ 0.85584694  0.14415306]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: NTY\n",
      "Probability: [ 0.9595878  0.0404122]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: NWF\n",
      "Probability: [ 0.96774656  0.03225348]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: PCY\n",
      "Probability: [ 0.97031873  0.02968132]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: SCL\n",
      "Probability: [ 0.96176755  0.03823242]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: SCZ\n",
      "Probability: [ 0.9666704   0.03332959]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: SEB\n",
      "Probability: [ 0.9678541   0.03214591]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: SGL\n",
      "Probability: [ 0.9591656   0.04083437]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: SGS\n",
      "Probability: [ 0.94611865  0.05388131]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: SML\n",
      "Probability: [ 0.4426692  0.5573307]\n",
      "Predict: 1\n",
      "----------------------------------------\n",
      "station: SNW\n",
      "Probability: [ 0.9433744   0.05662553]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: SPT\n",
      "Probability: [ 0.96242976  0.03757022]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: SSD\n",
      "Probability: [ 0.92658466  0.07341534]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: SSH\n",
      "Probability: [ 0.9324625  0.0675375]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: STY\n",
      "Probability: [ 0.55049014  0.4495098 ]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: TAI\n",
      "Probability: [ 0.9687942  0.0312058]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: TAI1\n",
      "Probability: [ 0.9694109   0.03058907]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: TAP\n",
      "Probability: [ 0.97007364  0.02992638]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: TAW\n",
      "Probability: [ 0.9654485   0.03455149]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: TCU\n",
      "Probability: [ 0.8490834   0.15091653]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: TTN\n",
      "Probability: [ 0.94266033  0.05733963]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: TWA\n",
      "Probability: [ 0.9699996   0.03000042]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: TWB1\n",
      "Probability: [ 0.97015834  0.02984161]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: TWC\n",
      "Probability: [ 0.97006094  0.02993901]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: TWD\n",
      "Probability: [ 0.9169972   0.08300278]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: TWE\n",
      "Probability: [ 0.9694937   0.03050637]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: TWF1\n",
      "Probability: [ 0.00691577  0.9930842 ]\n",
      "Predict: 1\n",
      "----------------------------------------\n",
      "station: TWK1\n",
      "Probability: [ 0.9700964   0.02990363]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: TWL\n",
      "Probability: [ 0.9213591  0.0786409]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: TWM1\n",
      "Probability: [ 0.9635021   0.03649784]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: TWQ1\n",
      "Probability: [ 0.43449757  0.5655024 ]\n",
      "Predict: 1\n",
      "----------------------------------------\n",
      "station: TWS1\n",
      "Probability: [ 0.96863985  0.03136019]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: TWT\n",
      "Probability: [ 0.85432476  0.14567527]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: TWY\n",
      "Probability: [ 0.97082806  0.02917194]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: TYC\n",
      "Probability: [ 0.9230582   0.07694183]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: WCH1\n",
      "Probability: [ 0.3934721  0.606528 ]\n",
      "Predict: 1\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "station: WDG\n",
      "Probability: [ 0.9686868   0.03131313]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: WDL\n",
      "Probability: [ 0.4102703   0.58972967]\n",
      "Predict: 1\n",
      "----------------------------------------\n",
      "station: WGK\n",
      "Probability: [ 0.50908756  0.49091247]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: WHF\n",
      "Probability: [ 0.523216    0.47678402]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: WLC\n",
      "Probability: [ 0.969729    0.03027095]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: WML\n",
      "Probability: [ 0.8975715   0.10242853]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: WNT\n",
      "Probability: [ 0.40787116  0.5921288 ]\n",
      "Predict: 1\n",
      "----------------------------------------\n",
      "station: WNT1\n",
      "Probability: [ 0.59177095  0.40822896]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: WPL\n",
      "Probability: [ 0.9110702   0.08892978]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: WSF\n",
      "Probability: [ 0.95541817  0.04458179]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: WSS\n",
      "Probability: [ 0.96856916  0.0314308 ]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: WTC\n",
      "Probability: [ 0.88376427  0.1162358 ]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: WTP\n",
      "Probability: [ 0.75384104  0.24615896]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: WWC\n",
      "Probability: [ 0.87300205  0.12699787]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: WWF\n",
      "Probability: [ 0.7177593   0.28224066]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: WYL\n",
      "Probability: [ 0.6828281  0.3171718]\n",
      "Predict: 0\n",
      "----------------------------------------\n",
      "station: YUS\n",
      "Probability: [ 0.00448198  0.995518  ]\n",
      "Predict: 1\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def plot_result(data_df_TN,data_df_FN,data_df_TP,data_df_FP,e_latlon,afile_name):\n",
    "    fig = pygmt.Figure()\n",
    "    fig.coast(\n",
    "        projection  = 'N12c',                         # 投影法とサイズ．メルカトルなら 'M12c' など．\n",
    "        region      = (119, 123, 21, 26),                 # 領域はリストかタプルで与える．\n",
    "        shorelines  = 'default,black',                    # 海岸線のペンの設定．\n",
    "        area_thresh = 100,                                # 細かい領域の描画下限 (km^2)\n",
    "        resolution  = 'f',                                # 'c', 'l', 'i', 'h', 'f' の順に高くなる\n",
    "        land        = '230/240/220',                      # 陸地の色\n",
    "        water       = '220/235/250',                      # 水の色\n",
    "        map_scale   = '100/32/32/400',                  # 距離スケールの水平・縦位置と距離サイズ\n",
    "        frame       = ['WSen+t\"predict_result_80\"', 'xafg', 'yafg']  # 南西に軸名・タイトル指定（+t) およびXY方向それぞれの軸情報\n",
    "    )  \n",
    "    #-------------------------------\n",
    "    #TN\n",
    "    if len(data_df_TN) != 0:\n",
    "        fig.plot(\n",
    "            x=data_df_TN.lon,\n",
    "            y=data_df_TN.lat,\n",
    "            style=\"t0.5c\",\n",
    "            color=\"blue\",\n",
    "            pen=\"green\",\n",
    "            label=f\"TN:{len(data_df_TN)}\"\n",
    "            )\n",
    "    #-------------------------------\n",
    "    #FN\n",
    "    if len(data_df_FN) != 0:\n",
    "        fig.plot(\n",
    "            x=data_df_FN.lon,\n",
    "            y=data_df_FN.lat,\n",
    "            style=\"s0.5c\",\n",
    "            color=\"red\",\n",
    "            pen=\"green\",\n",
    "            label=f\"FN:{len(data_df_FN)}\"\n",
    "            )\n",
    "    #-------------------------------\n",
    "    #TP\n",
    "    if len(data_df_TP) != 0:\n",
    "        fig.plot(\n",
    "            x=data_df_TP.lon,\n",
    "            y=data_df_TP.lat,\n",
    "            style=\"s0.5c\",\n",
    "            color=\"blue\",\n",
    "            pen=\"green\",\n",
    "            label=f\"TP:{len(data_df_TP)}\"\n",
    "            )\n",
    "    #-------------------------------\n",
    "\n",
    "    if len(data_df_FP) != 0:\n",
    "        fig.plot(\n",
    "            x=data_df_FP.lon,\n",
    "            y=data_df_FP.lat,\n",
    "            style=\"t0.5c\",\n",
    "            color=\"red\",\n",
    "            pen=\"green\",\n",
    "            label=f\"FP:{len(data_df_FP)}\"\n",
    "            )\n",
    "    #-------------------------------\n",
    "    \n",
    "    \n",
    "    fig.plot(\n",
    "        x=e_latlon[1],\n",
    "        y=e_latlon[0],\n",
    "        style=\"a0.5c\",\n",
    "        color=\"yellow\",\n",
    "        pen=\"green\",\n",
    "        label=\"Epicenter\"\n",
    "        )\n",
    "\n",
    "    fig.legend(position=\"JBl+jBL+o0.4c\")\n",
    "    fig.show()\n",
    "    fig.savefig(f\"{afile_name}_predict_result_80.jpg\")    \n",
    "\n",
    "class model_cnn():\n",
    "    def __init__(self, model=None, param_path=None):\n",
    "        self.model = model\n",
    "        checkpoint = torch.load(param_path, map_location=torch.device('cpu'))\n",
    "        self.model.load_state_dict(checkpoint)\n",
    "        self.model.eval()\n",
    "\n",
    "    def output(self, input_arr):\n",
    "        input_arr = np.expand_dims(input_arr,axis=0)\n",
    "        input_arr = torch.from_numpy(input_arr).float()\n",
    "        with torch.no_grad():\n",
    "            probs = torch.squeeze(F.softmax(self.model(input_arr), dim=1)).numpy()\n",
    "\n",
    "        return probs\n",
    "\n",
    "    def output_max(self, input_arr):\n",
    "        input_arr = np.expand_dims(input_arr,axis=0)\n",
    "        input_arr = torch.from_numpy(input_arr).float()\n",
    "        with torch.no_grad():\n",
    "            output = np.argmax(torch.squeeze(F.softmax(self.model(input_arr), dim=1)).numpy())\n",
    "\n",
    "        return output\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    result={}\n",
    "    num=int(input())\n",
    "    afile_name,pfile_name = batch_showname(path)\n",
    "    Pfile,Afile,Afile_se,e_latlon = apfile_read(pfile_name[num],afile_name[num])\n",
    "    data_factor,sta_lon_lat = factor()\n",
    "    Afile_se_data = cal_factor(Afile_se,data_factor)\n",
    "    Afile_se_5s,sta_P = cut_st(Afile_se_data,Pfile)\n",
    "    Afile_se_5s_data_123 = append_array(Afile_se_5s,sta_P)\n",
    "    pga_data = data_pga(Afile_se_5s_data_123,Pfile)\n",
    "    \n",
    "    for i,j in Afile_se_5s_data_123.items():\n",
    "        input_arr=j\n",
    "        model_cnn1 = model_cnn(model=model_cnn_cls.CNN5(), param_path=\"train_data_pga80_snr5_update_500_label4_model.ckpt\")\n",
    "        Probability = model_cnn1.output(input_arr)\n",
    "        Predict = model_cnn1.output_max(input_arr)\n",
    "        result[i]=[sta_lon_lat[i][0],sta_lon_lat[i][1],Probability[0],Probability[1],Predict,pga_data[i]]\n",
    "        print(\"station:\",i)\n",
    "        print(\"Probability:\", Probability)\n",
    "        print(\"Predict:\", Predict)\n",
    "        print(\"-\"*40)\n",
    "\n",
    "    result_txt(Pfile,afile_name[num],result)\n",
    "    data_df_TN,data_df_FN,data_df_TP,data_df_FP = data_read(afile_name[num],result,e_latlon)\n",
    "    plot_result(data_df_TN,data_df_FN,data_df_TP,data_df_FP,e_latlon,afile_name[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd39d365",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
